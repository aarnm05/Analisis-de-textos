---
title: "R Notebook"
output: html_notebook
---


```{r}
library(dplyr)
library(tidytext)
library(hunspell)
library(readxl)
hunspell::list_dictionaries()

espa=dictionary("C:/Users/emirr/Documents/Sortone/OneDrive/Git/Analisis-de-textos/mex/es_MX.dic")
costa = dictionary("C:/Users/emirr/Documents/Sortone/OneDrive/Git/Analisis-de-textos/costa/es_cr.dic")
cast = dictionary("C:/Users/emirr/Documents/Sortone/OneDrive/Git/Analisis-de-textos/cast/es_ES.dic")

dataset <- read_excel("dataset.xlsx")

k = hunspell(dataset$P1COM,dict = costa)


#cleantext function as defined by boski
#https://stackoverflow.com/questions/56026550/how-to-use-hunspell-package-to-suggest-correct-words-in-a-column-in-r

cleantext = function(x) {
  
  sapply(1:length(x), function(y) {
    bad = hunspell(x[y], dict = costa)[[1]]
    good = unlist(lapply(hunspell_suggest(bad,dict = costa), `[[`, 1))
    
    if (length(bad)) {
      for (i in 1:length(bad)) {
        x[y] <<- gsub(bad[i], good[i], x[y])
      }
    }
  })
  x
}

cleantext(dataset$P1COM[2])




custom_stop= data_frame(word = tm::stopwords("spanish"), #podemos hacerlo asÃ­
                                          lexicon = "custom")

kk = data.frame(participant =1:nrow(dataset) ,word = dataset$P1COM)
df_text <- kk %>% 
    unnest_tokens(input = "word",output = "word")

df_text2 = df_text %>%
  anti_join(custom_stop)  #elimina las palabras que coincidan dentro del registro de stopwords
  
ele = df_text2 %>% 
  group_by(participant) %>% 
  count(word,sort = T) 

```


```{r}
library(tidyr)
library(dplyr)
#df_text2 %>% 
 # pivot_wider(id_cols = participant)


elle = ele %>% 
  pivot_wider(id_cols = participant,names_from= word,values_from= n)
```

