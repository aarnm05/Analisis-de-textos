dataset <- read_excel("Sortone/OneDrive/U/Encuestas/PreguntaAbierta/dataset.xlsx")
library(dplyr)
library(dplyr)
library(tidytext)
library(hunspell)
library(readxl)
hunspell::list_dictionaries()
dictionary(lang = "es_cr")
dict.esp <- dictionary("es_cr")
dataset <- read_excel("Sortone/OneDrive/U/Encuestas/PreguntaAbierta/dataset.xlsx")
setwd("~/Sortone/OneDrive/Git/Analisis-de-textos")
dataset <- read_excel("Sortone/OneDrive/U/Encuestas/PreguntaAbierta/dataset.xlsx")
library(readxl)
dataset <- read_excel("~/dataset.xlsx")
dataset <- read_excel("/dataset.xlsx")
dataset <- read_excel("dataset.xlsx")
hunspell(dataset$P1COM,dict = "es_cr")
k = hunspell(dataset$P1COM,dict = "es_cr")
View(k)
k[[1]]
View(k)
k[[48]]
k = hunspell(dataset$P1COM,dict = dict.esp)
View(k)
View(k)
dataset$P1COM[1]
hunspell(dataset$P1COM[1],dict = dict.esp)
k = hunspell(dataset$P1COM[1],dict = dict.esp)
View(k)
k[[1]]
View(dataset)
hunspell(dataset$P1COM[1],dict = dict.esp)
hunspell("kars")
hunspell::list_dictionaries()
hunspell("kars r gud",dict = "en_US")
hunspell("kars are gud",dict = "en_US")
hunspell("kars are very gud",dict = "en_US")
dataset$P1COM[1]
hunspell(dataset$P1COM[1],dict = dict.esp)
hunspell::list_dictionaries()
hunspell::list_dictionaries()
dict.esp <- dictionary("es_ES")
library(dplyr)
library(dplyr)
library(tidytext)
library(dplyr)
library(tidytext)
library(hunspell)
library(readxl)
hunspell::list_dictionaries()
dict.esp <- dictionary("es_ES")
dict.esp <- dictionary("es_ES")
dataset <- read_excel("dataset.xlsx")
k = hunspell(dataset$P1COM[1],dict = dict.esp)
hunspell(dataset$P1COM[1],dict = dict.esp)
hunspell(dataset$P1COM[1],dict = dict.esp)
library(dplyr)
library(dplyr)
library(tidytext)
library(dplyr)
library(tidytext)
library(hunspell)
library(readxl)
hunspell::list_dictionaries()
hunspell(dataset$P1COM[1],dict = dict.esp)
hunspell::list_dictionaries()
espa=dictionary("~/espanol")
espa=dictionary("~/espanol/")
espa=dictionary("~/espanol/es_ES.dic")
setwd("~/Sortone/OneDrive/Git/Analisis-de-textos")
espa=dictionary("~/espanol/es_ES.dic")
espa=dictionary("C:/Users/emirr/Documents/Sortone/OneDrive/Git/Analisis-de-textos/espanol/es_ES.dic")
espa=dictionary("C:/Users/emirr/Documents/Sortone/OneDrive/Git/Analisis-de-textos/espanol/es_ES.dic")
hunspell::list_dictionaries()
espa
espa
espa=dictionary("C:/Users/emirr/Documents/Sortone/OneDrive/Git/Analisis-de-textos/espanol/es_ES.aff")
espa
espa=dictionary("C:/Users/emirr/Documents/Sortone/OneDrive/Git/Analisis-de-textos/espanol/es_ES.dic")
espa
espa=dictionary("C:/Users/emirr/Documents/Sortone/OneDrive/Git/Analisis-de-textos/mex/")
espa=dictionary("C:/Users/emirr/Documents/Sortone/OneDrive/Git/Analisis-de-textos/mex/es_MX.dic")
espa
hunspell(dataset$P1COM[1],dict = espa)
costa = dictionary("C:/Users/emirr/Documents/Sortone/OneDrive/Git/Analisis-de-textos/costa/es_cr.dic")
hunspell(dataset$P1COM[1],dict = costa)
hunspell(dataset$P1COM,dict = costa)
k = hunspell(dataset$P1COM,dict = costa)
View(k)
b = hunspell_suggest(k,dict=costa)
View(k)
k[[]]
k[]
b = hunspell_suggest(k[],dict=costa)
k[[1]]
hunspell_suggest(k[[1]],dict=costa)
hunspell_suggest(k[[1]],dict= espa)
cast = dictionary("C:/Users/emirr/Documents/Sortone/OneDrive/Git/Analisis-de-textos/costa/es_ES.dic")
cast = dictionary("C:/Users/emirr/Documents/Sortone/OneDrive/Git/Analisis-de-textos/cast/es_ES.dic")
hunspell_suggest(k[[1]],dict= cast)
hunspell_suggest(k[[1]],dict= costa)
k
k = hunspell(dataset$P1COM,dict = costa)
hunspell_suggest(k[[1]],dict= costa)
hunspell_suggest(k[[1]],dict= costa)[[1]][1]
hunspell_suggest(k[[1]],dict= costa)
k
k
View(k)
k[[1]]
hunspell_suggest(k[[1]],dict= costa)
hunspell_suggest(k[[1]],dict= costa)[[2]]
k[[1]]
k[[1]]
k
k[[1]] %>%
as.data.frame()
r = k[[1]] %>%
as.data.frame()
View(r)
r = k %>%
as.data.frame()
r = k %>%
as.data.frame()
View(r)
View(k)
cleantext = function(x) {
sapply(1:length(x), function(y) {
bad = hunspell(x[y], dict = costa)[[1]]
good = unlist(lapply(hunspell_suggest(bad), `[[`, 1))
if (length(bad)) {
for (i in 1:length(bad)) {
x[y] <<- gsub(bad[i], good[i], x[y])
}
}
})
x
}
cleantext(dataset$P1COM)
dataset$P1COM[1]
cleantext(dataset$P1COM[1])
cleantext = function(x) {
sapply(1:length(x), function(y) {
bad = hunspell(x[y], dict = costa)[[1]]
good = unlist(lapply(hunspell_suggest(bad,dict = costa), `[[`, 1))
if (length(bad)) {
for (i in 1:length(bad)) {
x[y] <<- gsub(bad[i], good[i], x[y])
}
}
})
x
}
cleantext(dataset$P1COM[1])
cleantext(dataset$P1COM[2])
